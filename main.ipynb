{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e55622-6c1e-4ce7-9b6a-66e7c05b9b36",
   "metadata": {},
   "source": [
    "# *** Choose your configuration: 0 docker, 1 cloudveneto ***"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 7,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "851da545-cf4b-47fd-b5ad-58b94f4cb1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 Docker, 1 CloudVeneto\n",
    "FIGHTER = 1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 1,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "c732a165-f0e4-4a4d-bda7-8d878cccce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# la porta dove vedere i jobs --- METTERE LA PROPRIA QUI ---\n",
<<<<<<< HEAD
    "SparkUI = 4043\n",
=======
    "SparkUI = 4040\n",
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
    "\n",
    "# nicolò 4040\n",
    "# marco  4041\n",
    "# francesco 4042\n",
    "# raffaele  4043\n",
    "\n",
    "# MASTER 8080 E' PER TUTTI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb13812-cf42-4545-975f-62e4e50efbe4",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 150%\">Porta 8080, voce Running Applications: puoi vedere se qualcuno ci sta lavorando.\n",
    "<br>\n",
    "Porta 8080, voce Workers: vedresti core e memoria usata se c'è qualcun'altro.</span>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 2,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "6c2fe857-f085-4f00-b986-b7e78e2dc6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"user_b\" # \"user_a\"  o  \"user_b\" (B SE SI E' I SECONDI A LAVORARCI)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 3,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "668376d9-f121-415a-a9ed-91f504dbf33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = 8 # 8 di 16, lasciare così se si lavora in due"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 4,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "57db6b01-e376-4361-9139-84de9663a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Npartition = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8da69cf-69b3-46be-95d3-5ee1682d1283",
   "metadata": {},
   "source": [
    "# *** Remember to close Spark Session ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5c59d-1172-405a-bafe-4754d41f8414",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233dd9bb-da1c-477d-898e-045d7c8589d3",
   "metadata": {},
   "source": [
    "sudo pkill -u $(whoami) -f \"jupyter-notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220edd20-24f9-44e7-9364-0ad0552a105f",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px; background-color:black; border:none;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d92118-3f45-4d38-a2a9-730f57634aac",
   "metadata": {},
   "source": [
    "# Creation of the Spark Session and Context"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 5,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "33a28d44-c369-4659-a27f-36556398bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PySpark core\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import SparkSession, DataFrame, Window\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# PySpark functions\n",
    "from pyspark.sql.functions import (\n",
    "    col, lit, expr, when, count, sum as spark_sum, abs as abs_,\n",
    "    round as spark_round, min as spark_min, max as spark_max, avg as spark_avg,\n",
    "    first, last, lag, row_number, desc, asc,\n",
    "    explode, sequence, from_unixtime, to_date, unix_timestamp,\n",
    "    window, min_by, mode, concat, monotonically_increasing_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "e8b76336-8f50-45ca-8605-531a1f1e9817",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 8,
   "id": "e8b76336-8f50-45ca-8605-531a1f1e9817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/01 06:56:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "source": [
    "if FIGHTER==0:\n",
    "\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"spark://spark-master:7077\") \\\n",
    "        .appName(\"ProjectDocker\") \\\n",
    "        .config(\"spark.executor.memory\", \"1000m\") \\\n",
    "        .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "        .config(\"spark.sql.execution.arrow.pyspark.fallback.enabled\", \"false\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "        # SE NON FUNZIONA TOGLI I DUE CONFIG DI ARROW\n",
    "\n",
    "        # .config(\"spark.executor.memory\", \"1500m\")\n",
    "        # .config(\"spark.executor.cores\", \"1\")\\\n",
    "        # .config(\"spark.executor.instances\", \"12\")\\\n",
    "        # .config(\"spark.cores.max\", \"12\")\\\n",
    "        # .config(\"spark.default.parallelism\", \"24\")\\\n",
    "        # .config(\"spark.sql.adaptive.enabled\", \"true\")\\\n",
    "\n",
    "elif FIGHTER==1:\n",
    "\n",
    "        os.environ[\"PYSPARK_PYTHON\"] = \"/opt/miniconda3/bin/python\"\n",
    "        os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/opt/miniconda3/bin/python\"\n",
    "        \n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"ProjectCloudVeneto\") \\\n",
    "            .master(\"spark://10.67.22.135:7077\") \\\n",
    "            .config(\"spark.scheduler.mode\", \"FAIR\") \\\n",
    "            .config(\"spark.scheduler.pool\", user) \\\n",
    "            .config(\"spark.scheduler.allocation.file\", \"file:///usr/local/spark/conf/fairscheduler.xml\") \\\n",
    "            .config(\"spark.cores.max\", core) \\\n",
    "            .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "            .config(\"spark.sql.execution.arrow.pyspark.fallback.enabled\", \"false\") \\\n",
    "            .config(\"spark.dynamicAllocation.enabled\", \"false\") \\\n",
    "            .config(\"spark.shuffle.service.enabled\", \"false\") \\\n",
    "            .config(\"spark.ui.port\", SparkUI) \\\n",
    "            .getOrCreate()\n",
    "    \n",
    "else : print(\"Better choose an available fighter, you little bastard.\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5025883-f632-4dd6-a155-cc400748ff88",
   "metadata": {},
   "source": [
    "# Dataset upload and partition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9008e-6664-47e2-b7e2-6642464cf09e",
   "metadata": {},
   "source": [
    "### General Dataset"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 9,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "a4f13136-99cd-4587-b41a-939782920223",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIGHTER==0:\n",
    "    df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/ProvePreliminari/SW-106.csv\")\n",
    "\n",
    "elif FIGHTER==1:\n",
    "    df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"file:///mnt/shared/dataset.csv\")\n",
    "\n",
    "else:\n",
    "    print(\"Better choose an available fighter, you little bastard\")\n",
    "\n",
    "df = df.repartition(Npartition)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 10,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "81051779-dc36-4e67-980b-46843f3826aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect dataset\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "4d0acae8-0964-47f7-938d-762a11b32d5b",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 11,
   "id": "4d0acae8-0964-47f7-938d-762a11b32d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=======================================================> (38 + 1) / 39]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+------+-----+\n",
      "|when         |hwid  |metric|value|\n",
      "+-------------+------+------+-----+\n",
      "|1602247812642|SW-065|S100  |95   |\n",
      "|1602544565258|SW-065|P7    |260  |\n",
      "|1602899382279|SW-065|S9    |0    |\n",
      "|1602124576237|SW-065|S143  |0    |\n",
      "|1602959870262|SW-065|S49   |0    |\n",
      "|1602532679018|SW-065|S100  |94   |\n",
      "|1602119481602|SW-065|S137  |0    |\n",
      "|1602270047321|SW-065|S50   |0    |\n",
      "|1601843325781|SW-065|S106  |0    |\n",
      "|1601750843738|SW-065|S110  |0    |\n",
      "+-------------+------+------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "source": [
    "# inspect dataset\n",
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb6ebcb-2a1e-4c9d-9f15-2600f04883f4",
   "metadata": {},
   "source": [
    "### Focus on one hardware at time"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 12,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "13a9d3a5-9805-4732-868c-b40007b6dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert milliseconds into seconds\n",
    "df = df.withColumn(\"when\", spark_round(col(\"when\") / 1000).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b274cc0f-fa59-4034-8939-d44866d42681",
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  hwid|\n",
      "+------+\n",
      "|SW-088|\n",
      "|SW-106|\n",
      "|SW-065|\n",
      "|SW-115|\n",
      "+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "source": [
    "hwid_list = df.select(\"hwid\").distinct()\n",
    "hwid_list.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 14,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "91d73c3d-8f98-440b-84d8-3c650cd8db8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# CHANGE HERE HARDWARE TO ANALYZE\n",
    "hardware = \"SW-106\"\n",
    "df_hw = df  .filter(col(\"hwid\") == hardware)\\\n",
    "            .groupBy(\"when\")\\\n",
    "            .pivot(\"metric\")\\\n",
    "            .agg(first(\"value\"))\\\n",
    "            .withColumn(\"time\", from_unixtime(col(\"when\")))\\\n",
    "            .orderBy(\"when\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 15,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "00e0ae50-018f-4319-8f98-1902941961ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/01 06:58:54 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "# momentarily persist this dataframe, then we'll unpersist\n",
    "df_hw = df_hw.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74fc95-61c9-4880-b4ec-324cc1794705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we trigger persist transformation\n",
    "df_hw.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99b20f-f39e-496f-b541-1f3ab4a37092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_hw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 18,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "28b071f9-4c55-448f-87ed-ea874e8e764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = [\"when\", \"time\", \"S117\", \"S118\", \"S169\", \"S170\"]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 19,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "6b4fa421-6c3d-4d9e-a18e-44a3f08c7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 rows\n",
    "df_hw.select(*selected_cols).orderBy(col(\"time\").asc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63cd73-76c6-4746-a301-24bf44285ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show last 5 rows\n",
    "df_hw.select(*selected_cols).orderBy(col(\"time\").desc()).limit(5).orderBy(col(\"time\").asc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8c3426-d368-4a67-8b7f-6088fce72d7b",
   "metadata": {},
   "source": [
    "Usefull function to inspect a general dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ef893-9a57-4d41-8e88-f9afa940ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect(df: DataFrame, sensors: list, start: int, end: int) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Filter a DataFrame by time range and select specified sensor columns.\n",
    "\n",
    "    Args:\n",
    "        df:        Input Spark DataFrame with 'when' and 'time' columns.\n",
    "        sensors:   List of sensor column names to include (e.g., ['S117', 'S118']).\n",
    "        start:  Start of the time range (Unix timestamp, in seconds).\n",
    "        end:    End of the time range (Unix timestamp, in seconds).\n",
    "\n",
    "    Returns:\n",
    "        Filtered Spark DataFrame with columns ['time', 'when', ...sensors].\n",
    "    \"\"\"\n",
    "    selected_columns = [\"when\",\"time\"] + sensors\n",
    "\n",
    "    return (\n",
    "        df.select(*selected_columns)\n",
    "          .filter((col(\"when\") >= start) & (col(\"when\") <= end))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e95f0b-c822-4459-9734-fab239bd6b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect(df_hw, sensors=[\"S117\"], start=1601526622, end=1601531000).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f446543-3012-4f64-8855-04f3a94b9725",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Timestamp analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0f6fc-7d52-4f8b-9dab-a31bc4041a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_time_differences(df, when_col=\"when\", max_collect=1_000_000):\n",
    "    \"\"\"\n",
    "    Computes time differences (Δwhen) between consecutive rows in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Spark DataFrame with a time column (e.g., 'when').\n",
    "        when_col (str): Name of the time column to compute differences on.\n",
    "        max_collect (int): Threshold to safely collect diffs to driver.\n",
    "\n",
    "    Returns:\n",
    "        rdd_diff (RDD): RDD of differences (current - previous).\n",
    "    \"\"\"\n",
    "    rdd_times = df.select(when_col).rdd.map(lambda row: row[when_col])\n",
    "    rdd_shifted = rdd_times.zipWithIndex().map(lambda x: (x[1], x[0]))  # (index, time)\n",
    "    rdd_prev = rdd_shifted.map(lambda x: (x[0] + 1, x[1]))              # shift by +1 index\n",
    "    rdd_joined = rdd_shifted.join(rdd_prev).sortByKey()\n",
    "    rdd_diff = rdd_joined.map(lambda x: x[1][0] - x[1][1])\n",
    "\n",
    "    num_diffs = rdd_diff.count()\n",
    "    print(f\"Number of time differences: {num_diffs}\")\n",
    "\n",
    "    if num_diffs < max_collect:\n",
    "        return rdd_diff\n",
    "    else:\n",
    "        print(\"Too many differences to collect safely.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d3298f-a690-4ad9-87ce-84babcaf15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_diff_summary(rdd_diff, spark, top_n=5):\n",
    "    \"\"\"\n",
    "    Summarizes the RDD of time differences into a frequency table and prints top/bottom values.\n",
    "\n",
    "    Args:\n",
    "        rdd_diff (RDD): RDD of integer time differences.\n",
    "        spark (SparkSession): Active Spark session.\n",
    "        top_n (int): Number of rows to show from top and bottom.\n",
    "\n",
    "    Returns:\n",
    "        df_freq (DataFrame): DataFrame with columns ['diff', 'count'].\n",
    "    \"\"\"\n",
    "    if rdd_diff is None:\n",
    "        print(\"No differences available to summarize.\")\n",
    "        return None\n",
    "\n",
    "    df_freq = rdd_diff.map(lambda d: (d, 1)) \\\n",
    "                      .reduceByKey(lambda a, b: a + b) \\\n",
    "                      .toDF([\"diff\", \"count\"]) \\\n",
    "                      .orderBy(\"diff\")\n",
    "\n",
    "    print(f\"\\n{top_n} smallest time differences:\")\n",
    "    df_freq.show(top_n, truncate=False)\n",
    "\n",
    "    print(f\"\\n{top_n} largest time differences:\")\n",
    "    df_freq.orderBy(\"diff\", ascending=False).show(top_n, truncate=False)\n",
    "\n",
    "    return df_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23163b-0c73-4674-8401-5024b4276d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute time differences\n",
    "rdd_diff = compute_time_differences(df_hw)\n",
    "\n",
    "# Summarize and print top/bottom time gaps\n",
    "df_diff_summary = time_diff_summary(rdd_diff, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a988ee9a-11ad-4296-bb6b-4af7dfda97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff_histogram(differences, min_diff, max_diff, delta):\n",
    "    \n",
    "    filtered = [d for d in differences if min_diff <= d <= max_diff]\n",
    "\n",
    "    bins = int((max_diff - min_diff) / delta)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(filtered, bins=bins, color=\"steelblue\", edgecolor=\"black\")\n",
    "    plt.title(f\"Time Difference Events (range {min_diff} - {max_diff} [s])\")\n",
    "    plt.xlabel(\"Time difference [s]\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    #plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da52466-b638-4f78-a69b-675637894c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = rdd_diff.collect() # check previously the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58fc7ad-7b64-43ba-a24a-c792ebcbba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diff_histogram(differences=diffs, min_diff=0, max_diff=180, delta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddab6d-ec14-4fa8-852b-1b82c8e37477",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diff_histogram(differences=diffs, min_diff=180, max_diff=4000, delta=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a42ed-503b-48f1-8424-3797e172ef8a",
   "metadata": {},
   "source": [
    "# Handling missing data & gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf468733-9925-4c0d-9103-0fe3bb49a50c",
   "metadata": {},
   "source": [
    "### Create final grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dbacf3-8b46-4a7e-8c50-d58ef6cffb72",
   "metadata": {},
   "source": [
    "Direi di tenere questa funzione \"FillGaps\" e continuare ad implementare partendo da questa"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 25,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "95a5fead-148a-4ea9-ac9d-99c24593657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = 60 #seconds"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 64,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "035e45e5-4245-4719-b11f-30dec4d4afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FillGaps(\n",
    "    df: DataFrame,\n",
    "    sensors: list = None,\n",
    "    interval: int = 60,\n",
    "    modality: str = 'auto',\n",
    "    fill_null: bool = False\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregates sensor data into fixed-size time windows and fills missing values using Spark.\n",
    "\n",
    "    Args:\n",
    "        df: Spark DataFrame with a 'when' column (UNIX timestamp in seconds).\n",
    "        sensors: List of sensor column names. If None, inferred from all columns except 'when' and 'time'.\n",
    "        interval: Window size in seconds.\n",
    "        modality: Aggregation method: 'mean', 'min', 'max', 'mode', or 'auto'.\n",
    "        fill_null: If True, fills missing values using forward and backward fill in Spark.\n",
    "\n",
    "    Returns:\n",
    "        Aggregated and optionally gap-filled DataFrame, with a `when` column at the center of the window\n",
    "        and a `window_id` column that uniquely identifies each time window.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Infer sensor columns if not provided\n",
    "    if sensors is None:\n",
    "        sensors = [c for c in df.columns if c not in (\"when\", \"time\")]\n",
    "\n",
    "    # 2. Add timestamp column\n",
    "    df_ts = df.withColumn(\"timestamp\", from_unixtime(col(\"when\")).cast(\"timestamp\"))\n",
    "\n",
    "    # 3. Create time window\n",
    "    df_windowed = df_ts.withColumn(\"time_window\", window(\"timestamp\", f\"{interval} seconds\"))\n",
    "\n",
    "    # 4. Aggregate using selected modality\n",
    "    if modality == \"mode\":\n",
    "        # Special case: MODE needs groupBy and count per window + sensor\n",
    "        aggs = []\n",
    "        for s in sensors:\n",
    "            mode_df = (\n",
    "                df_windowed.groupBy(\"time_window\", s)\n",
    "                .agg(count(\"*\").alias(\"cnt\"))\n",
    "                .withColumn(\"rank\", row_number().over(\n",
    "                    Window.partitionBy(\"time_window\").orderBy(desc(\"cnt\"))\n",
    "                ))\n",
    "                .filter(col(\"rank\") == 1)\n",
    "                .select(\"time_window\", col(s).alias(s))\n",
    "            )\n",
    "            if not aggs:\n",
    "                result_df = mode_df\n",
    "            else:\n",
    "                result_df = result_df.join(mode_df, on=\"time_window\", how=\"outer\")\n",
    "    else:\n",
    "        aggs = []\n",
    "        for s in sensors:\n",
    "            if modality == \"mean\":\n",
    "                agg_func = spark_avg(col(s)).alias(s)\n",
    "            elif modality == \"min\":\n",
    "                agg_func = spark_min(col(s)).alias(s)\n",
    "            elif modality == \"max\":\n",
    "                agg_func = spark_max(col(s)).alias(s)\n",
    "            elif modality == \"auto\":\n",
    "                stats = df.selectExpr(f\"min({s}) as min\", f\"max({s}) as max\").first()\n",
    "                is_binary = stats[\"min\"] is not None and stats[\"max\"] is not None and 0 <= stats[\"min\"] and stats[\"max\"] <= 1\n",
    "                if s in [\"A5\", \"A9\"] or is_binary:\n",
    "                    agg_func = spark_max(col(s)).alias(s)\n",
    "                else:\n",
    "                    agg_func = spark_avg(col(s)).alias(s)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported modality: {modality}\")\n",
    "            aggs.append(agg_func)\n",
    "\n",
    "        result_df = (\n",
    "            df_windowed\n",
    "            .groupBy(\"time_window\")\n",
    "            .agg(*aggs)\n",
    "        )\n",
    "\n",
    "    # 5. Add window_start, window_end, and 'when' as center of window\n",
    "    result_df = (\n",
    "        result_df\n",
    "        .withColumn(\"window_start\", col(\"time_window.start\"))\n",
    "        .withColumn(\"window_end\", col(\"time_window.end\"))\n",
    "        .withColumn(\"when\", expr(\"unix_timestamp(window_start) + int((unix_timestamp(window_end) - unix_timestamp(window_start)) / 2)\"))\n",
    "        .drop(\"time_window\")\n",
    "        .orderBy(\"when\")\n",
    "    )\n",
    "\n",
    "    # 6. Fill nulls if requested using Spark-native ffill + bfill\n",
    "    if fill_null:\n",
    "        w_forward = Window.orderBy(\"when\").rowsBetween(Window.unboundedPreceding, 0)\n",
    "        w_backward = Window.orderBy(\"when\").rowsBetween(0, Window.unboundedFollowing)\n",
    "        for s in sensors:\n",
    "            result_df = result_df.withColumn(s, last(col(s), ignorenulls=True).over(w_forward))\n",
    "            result_df = result_df.withColumn(s, first(col(s), ignorenulls=True).over(w_backward))\n",
    "\n",
    "    # 7. Add window_id as progressive row number\n",
    "    result_df = result_df.withColumn(\"window_id\", monotonically_increasing_id())\n",
    "\n",
    "    return result_df.select([\"window_id\", \"when\", \"window_start\", \"window_end\"] + sensors)\n",
    "\n",
    "    # 6. Optionally fill nulls using Pandas (costly)\n",
    "    # if fill_null:\n",
    "    #     pandas_df = result_df.toPandas()\n",
    "    #     pandas_df = pandas_df.ffill().bfill()\n",
    "    #     return spark.createDataFrame(pandas_df)\n",
    "    # else:\n",
    "    #     return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209d6a5b-bea0-44f5-9467-cc3ee04c8eb0",
   "metadata": {},
   "source": [
    "Already added conversion of A5 and A9 sensors, and overheating control function."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 65,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "fcb321d1-2adb-49b0-8964-5954fc64d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_alarm_bits(df: DataFrame, columns=[\"A5\", \"A9\"], bits=[6, 7, 8]) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts specific bits (1-indexed, left to right) from the given integer alarm columns\n",
    "    and adds them as new columns in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: Input Spark DataFrame.\n",
    "        columns: List of alarm column names (e.g., [\"A5\", \"A9\"]).\n",
    "        bits: List of bit positions to extract (left-to-right, 1-based index).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with additional columns like \"6-A5\", \"7-A9\", etc.\n",
    "    \"\"\"\n",
    "    for col_name in columns:\n",
    "        for bit in bits:\n",
    "            # Convert left-to-right to right-to-left (bit 1 is MSB → position 15)\n",
    "            bit_from_right = 16 - bit\n",
    "            df = df.withColumn(\n",
    "                f\"{bit}-{col_name}\",\n",
    "                ((col(col_name).bitwiseAND(1 << bit_from_right)) > 0).cast(\"int\")\n",
    "            )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 66,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "19bba7e7-48ab-48fa-8c62-38f68920310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_overheating_flag(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a binary column 'overheating' which is 1 if any of bits 6, 7, or 8 of A5 or A9 is 1.\n",
    "\n",
    "    Args:\n",
    "        df: Spark DataFrame with bit columns already extracted.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with 'overheating' column added.\n",
    "    \"\"\"\n",
    "    overheating_bits = [f\"{b}-{s}\" for s in [\"A5\", \"A9\"] for b in [6, 7, 8]]\n",
    "    condition = sum([col(c) for c in overheating_bits]) > 0\n",
    "    return df.withColumn(\"overheating\", when(condition, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 67,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "c0ad2a85-6f6d-4af8-abff-0891fc6dae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# #2° MODALITA' USO FUNZIONE FillGaps\n",
    "# #Doesn't seem to be particularly dependent on the number of metrics (9 seconds with 1, 13 seconds with 15)\n",
    "# sensors=['S117', 'S118',  'S169', 'S170', 'S41', 'ComError']#, 'A5', 'A9', 'P18', 'P2', 'P5', 'P6', 'P7', 'P8', 'P9', 'S1']\n",
    "# GridDF = FillGaps(df_hw, sensors=sensors, modality=\"min\", interval=60)\n",
    "# GridDF.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "84b10bd4-2fae-45c1-9fab-389d96d8bd94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
=======
   "execution_count": 91,
   "id": "84b10bd4-2fae-45c1-9fab-389d96d8bd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------------------+-------------------+----+----+--------+---+-----+---+-----+-----+-----+---+-----+-----+-----+-----+-----+---+----+----+-----+-----+----+-----+----+-----+---+----+----+----+----+----+----+----+-----+----+-----+----+----+----+----+-----+----+-----+----+----+-----+-----+---+----+----+----+-----+-----+---+----+-----+----+-----+----+----+---+----+----+----+----+----+----+----+-----+----+-------+----+----+---+---+------+------+------+------+------+------+---+----+---+---+---+-----+-----+----+-----+---+---+---+-----+-----+---+---+---+---+---+---+---+---+-----+---+---+---+---+------+----+-----+---+---+-----+----+----+-----+---+-----+----+----+---+----+----+----+---+---+---+---+---+---+---+---+---+----+----+----+----+----+----+\n",
      "|window_id|when      |window_start       |window_end         |A5  |A9  |ComError|P1 |P10  |P15|P16  |P17  |P18  |P2 |P5   |P6   |P7   |P8   |P9   |S1 |S10 |S100|S101 |S102 |S106|S107 |S108|S109 |S11|S110|S112|S113|S114|S115|S117|S118|S122 |S123|S124 |S125|S126|S127|S128|S129 |S130|S137 |S138|S140|S143 |S147 |S15|S151|S154|S157|S158 |S159 |S16|S163|S164 |S165|S166 |S167|S169|S17|S170|S171|S172|S173|S174|S175|S176|S178 |S179|S180   |S181|S183|S19|S2 |S201  |S202  |S203  |S204  |S205  |S206  |S25|S3  |S33|S34|S35|S37  |S39  |S40 |S41  |S42|S43|S45|S46  |S47  |S49|S5 |S50|S53|S54|S55|S56|S57|S6   |S63|S64|S69|S7 |S70   |S71 |S72  |S73|S8 |S80  |S81 |S83 |S86  |S9 |S90  |S94 |S97 |SA1|SA10|SA11|SA12|SA2|SA3|SA4|SA5|SA6|SA7|SA8|SA9|SW |6-A5|7-A5|8-A5|6-A9|7-A9|8-A9|\n",
      "+---------+----------+-------------------+-------------------+----+----+--------+---+-----+---+-----+-----+-----+---+-----+-----+-----+-----+-----+---+----+----+-----+-----+----+-----+----+-----+---+----+----+----+----+----+----+----+-----+----+-----+----+----+----+----+-----+----+-----+----+----+-----+-----+---+----+----+----+-----+-----+---+----+-----+----+-----+----+----+---+----+----+----+----+----+----+----+-----+----+-------+----+----+---+---+------+------+------+------+------+------+---+----+---+---+---+-----+-----+----+-----+---+---+---+-----+-----+---+---+---+---+---+---+---+---+-----+---+---+---+---+------+----+-----+---+---+-----+----+----+-----+---+-----+----+----+---+----+----+----+---+---+---+---+---+---+---+---+---+----+----+----+----+----+----+\n",
      "|0        |1601510430|2020-10-01 00:00:00|2020-10-01 00:01:00|NULL|NULL|NULL    |2.0|450.0|0  |100.0|400.0|450.0|0  |300.0|180.0|260.0|150.0|300.0|0  |70.0|81.0|211.0|211.5|0   |452.0|0   |616.0|0  |0   |1   |1   |0   |0   |0   |1   |410.0|1.0 |-81.5|57.0|24.0|0   |51.0|110.0|1.0 |110.0|47.0|86.0|100.0|100.0|0  |40.5|84.5|79.0|208.0|211.5|0  |0   |451.0|0   |622.0|0   |0   |0  |1   |1   |1   |0   |0   |0   |0   |408.5|1.0 |65454.0|57.0|0   |0  |2.0|7182.0|7179.0|7179.0|7182.0|7179.0|7179.0|0  |91.0|1  |0  |1  |701.0|103.0|74.0|234.0|0  |0  |0  |451.0|452.5|0  |4.0|0  |0  |0  |1  |0  |0  |450.0|0  |0  |0  |0  |1000.0|50.0|109.0|1.0|0  |109.0|40.0|72.5|100.0|0.0|100.0|39.5|77.5|0.0|0.0 |0   |0   |0.0|0  |0  |0  |0.0|0  |0  |0  |1  |NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "+---------+----------+-------------------+-------------------+----+----+--------+---+-----+---+-----+-----+-----+---+-----+-----+-----+-----+-----+---+----+----+-----+-----+----+-----+----+-----+---+----+----+----+----+----+----+----+-----+----+-----+----+----+----+----+-----+----+-----+----+----+-----+-----+---+----+----+----+-----+-----+---+----+-----+----+-----+----+----+---+----+----+----+----+----+----+----+-----+----+-------+----+----+---+---+------+------+------+------+------+------+---+----+---+---+---+-----+-----+----+-----+---+---+---+-----+-----+---+---+---+---+---+---+---+---+-----+---+---+---+---+------+----+-----+---+---+-----+----+----+-----+---+-----+----+----+---+----+----+----+---+---+---+---+---+---+---+---+---+----+----+----+----+----+----+\n",
      "only showing top 1 row\n",
      "\n",
      "CPU times: user 189 ms, sys: 95 ms, total: 284 ms\n",
      "Wall time: 28.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/01 08:15:56 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "source": [
    "%%time\n",
    "\n",
    "#1° MODALITA' USO FUNZIONE FillGaps\n",
    "# Fill sensor gaps\n",
    "df_grid = FillGaps(df_hw, interval=frequency, modality=\"auto\", fill_null=False)\n",
    "\n",
    "# Extract bits from alarms\n",
    "df_grid = extract_alarm_bits(df_grid, columns=[\"A5\", \"A9\"], bits=[6, 7, 8])\n",
    "\n",
    "# Add 'overheating' column\n",
    "# --- IMPLEMENTATA GIA (E' RICHIESTA PIU' AVANTI) ORA NON SERVE\n",
    "# df_final = add_overheating_flag(df_final)\n",
    "\n",
    "# Now persist the result\n",
    "df_final = df_grid.persist()\n",
    "\n",
    "# Trigger persist\n",
    "df_final.show(1, truncate = False)\n",
    "\n",
    "# Unpersist original dataframe\n",
    "# --- PER IL MOMENTO DIREI DI TENERLO CON IL PERSIST CHE E' PRATICO PER LA FASE DI SVILUPPO PER RICONTROLLARE LE COSE SUL DATAFRAME ORIGINARIO\n",
    "# df_hw.unpersist()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "32363f5b-f834-41c1-a348-a8b31d4ed446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
=======
   "execution_count": 92,
   "id": "32363f5b-f834-41c1-a348-a8b31d4ed446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------------------+-------------------+----+----+----+----+----+----+----+-----+----+----+\n",
      "|window_id|when      |window_start       |window_end         |S110|S112|S113|S114|S115|S117|S118|S122 |A9  |8-A9|\n",
      "+---------+----------+-------------------+-------------------+----+----+----+----+----+----+----+-----+----+----+\n",
      "|0        |1601510430|2020-10-01 00:00:00|2020-10-01 00:01:00|0   |1   |1   |0   |0   |0   |1   |410.0|NULL|NULL|\n",
      "|1        |1601510490|2020-10-01 00:01:00|2020-10-01 00:02:00|0   |1   |1   |0   |0   |0   |1   |406.5|NULL|NULL|\n",
      "|2        |1601510550|2020-10-01 00:02:00|2020-10-01 00:03:00|0   |1   |1   |0   |0   |0   |1   |409.0|NULL|NULL|\n",
      "|3        |1601510610|2020-10-01 00:03:00|2020-10-01 00:04:00|0   |1   |1   |0   |0   |0   |1   |406.5|NULL|NULL|\n",
      "|4        |1601510670|2020-10-01 00:04:00|2020-10-01 00:05:00|0   |1   |1   |0   |0   |0   |1   |406.5|NULL|NULL|\n",
      "|5        |1601510730|2020-10-01 00:05:00|2020-10-01 00:06:00|0   |1   |1   |0   |0   |0   |1   |407.5|NULL|NULL|\n",
      "|6        |1601510790|2020-10-01 00:06:00|2020-10-01 00:07:00|0   |1   |1   |1   |0   |0   |1   |0.0  |NULL|NULL|\n",
      "|7        |1601510850|2020-10-01 00:07:00|2020-10-01 00:08:00|0   |1   |0   |1   |0   |0   |1   |0.0  |NULL|NULL|\n",
      "|8        |1601510910|2020-10-01 00:08:00|2020-10-01 00:09:00|0   |1   |0   |1   |0   |0   |1   |0.0  |NULL|NULL|\n",
      "|9        |1601510970|2020-10-01 00:09:00|2020-10-01 00:10:00|0   |1   |0   |1   |0   |0   |1   |0.0  |NULL|NULL|\n",
      "|10       |1601511030|2020-10-01 00:10:00|2020-10-01 00:11:00|0   |1   |0   |1   |0   |1   |1   |0.0  |NULL|NULL|\n",
      "|11       |1601511090|2020-10-01 00:11:00|2020-10-01 00:12:00|0   |1   |0   |1   |0   |1   |0   |0.0  |NULL|NULL|\n",
      "|12       |1601511150|2020-10-01 00:12:00|2020-10-01 00:13:00|0   |1   |0   |1   |0   |1   |0   |0.0  |NULL|NULL|\n",
      "|13       |1601511270|2020-10-01 00:14:00|2020-10-01 00:15:00|0   |1   |0   |1   |0   |1   |0   |0.0  |0   |0   |\n",
      "|14       |1601511330|2020-10-01 00:15:00|2020-10-01 00:16:00|0   |1   |0   |1   |0   |1   |0   |0.0  |NULL|NULL|\n",
      "|15       |1601511390|2020-10-01 00:16:00|2020-10-01 00:17:00|0   |1   |0   |1   |0   |1   |0   |0.0  |NULL|NULL|\n",
      "|16       |1601511570|2020-10-01 00:19:00|2020-10-01 00:20:00|0   |1   |1   |0   |0   |1   |0   |364.5|NULL|NULL|\n",
      "|17       |1601511630|2020-10-01 00:20:00|2020-10-01 00:21:00|0   |1   |1   |0   |0   |1   |0   |379.0|NULL|NULL|\n",
      "|18       |1601511690|2020-10-01 00:21:00|2020-10-01 00:22:00|0   |1   |1   |0   |0   |1   |0   |384.0|NULL|NULL|\n",
      "|19       |1601511750|2020-10-01 00:22:00|2020-10-01 00:23:00|0   |1   |1   |0   |0   |1   |0   |385.0|NULL|NULL|\n",
      "|20       |1601511810|2020-10-01 00:23:00|2020-10-01 00:24:00|0   |1   |1   |0   |0   |1   |0   |389.0|NULL|NULL|\n",
      "|21       |1601511930|2020-10-01 00:25:00|2020-10-01 00:26:00|0   |1   |1   |0   |0   |1   |0   |384.0|NULL|NULL|\n",
      "|22       |1601511990|2020-10-01 00:26:00|2020-10-01 00:27:00|0   |1   |1   |0   |0   |1   |0   |385.0|NULL|NULL|\n",
      "|23       |1601512110|2020-10-01 00:28:00|2020-10-01 00:29:00|0   |1   |0   |1   |0   |1   |0   |0.0  |NULL|NULL|\n",
      "|24       |1601512170|2020-10-01 00:29:00|2020-10-01 00:30:00|0   |1   |0   |1   |0   |1   |0   |0.0  |NULL|NULL|\n",
      "|25       |1601512230|2020-10-01 00:30:00|2020-10-01 00:31:00|0   |1   |0   |1   |0   |1   |0   |0.0  |NULL|NULL|\n",
      "|26       |1601512290|2020-10-01 00:31:00|2020-10-01 00:32:00|0   |1   |0   |1   |0   |1   |0   |0.0  |NULL|NULL|\n",
      "|27       |1601512410|2020-10-01 00:33:00|2020-10-01 00:34:00|0   |1   |0   |1   |0   |1   |0   |0.0  |NULL|NULL|\n",
      "|28       |1601512470|2020-10-01 00:34:00|2020-10-01 00:35:00|0   |1   |0   |1   |0   |1   |0   |0.0  |NULL|NULL|\n",
      "|29       |1601512530|2020-10-01 00:35:00|2020-10-01 00:36:00|0   |1   |0   |1   |0   |1   |0   |0.0  |NULL|NULL|\n",
      "+---------+----------+-------------------+-------------------+----+----+----+----+----+----+----+-----+----+----+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "source": [
    "df_final.select(\"window_id\",\"when\",\"window_start\",\"window_end\",\"S110\",\"S112\",\"S113\",\"S114\",\"S115\",\"S117\",\"S118\",\"S122\",\"A9\",\"8-A9\").show(30, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "833128e3-1b4a-4d52-832b-1496e9e726d0",
   "metadata": {
    "scrolled": true
   },
=======
   "execution_count": 35,
   "id": "833128e3-1b4a-4d52-832b-1496e9e726d0",
   "metadata": {},
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "outputs": [],
   "source": [
    "#inspect(df_hw, sensors=[\"S110\",\"S112\",\"S113\",\"S114\",\"S115\",\"S117\",\"S118\",\"S122\",\"A9\"], start=1601510400, end=1601512550).show(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82ff09-e754-431e-89d5-8e50e13dd429",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Block Structure (FRANCESCO)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 104,
   "id": "eb77fdb3-61bd-43f4-a5c7-000461168075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the dataset, creates another column with the block id given the max_interval between two data points\n",
    "def BuildBlocks(df, max_interval):\n",
    "\n",
    "    #Computes a new column with the time difference between next timestamp\n",
    "    w = Window.partitionBy(lit(1)).orderBy(\"when\")\n",
    "\n",
    "    df = df.withColumn(\"Prev_TimeStamp\", lag(\"when\").over(w))\n",
    "    df = df.withColumn(\"TimeDiff_s\", col(\"when\") - col(\"Prev_TimeStamp\"))\n",
    "\n",
    "    #Handle the first NULL value \n",
    "    df = df.withColumn(\"TimeDiff_s\", coalesce(col(\"TimeDiff_s\"), lit(60)))\n",
    "\n",
    "    #Define blocks_id\n",
    "    df = df.withColumn(\"CheckNewBlock\", when(col(\"TimeDiff_s\") > max_interval, 1).otherwise(0))\n",
    "    df = df.withColumn(\"BlockID\", spark_sum(\"CheckNewBlock\").over(w))\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a95e46ba-92be-4850-8d1b-c06076999a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------------------+-------------------+----------+-------+\n",
      "|window_id|      when|       window_start|         window_end|TimeDiff_s|BlockID|\n",
      "+---------+----------+-------------------+-------------------+----------+-------+\n",
      "|        0|1601510430|2020-10-01 00:00:00|2020-10-01 00:01:00|        60|      0|\n",
      "|        1|1601510490|2020-10-01 00:01:00|2020-10-01 00:02:00|        60|      0|\n",
      "|        2|1601510550|2020-10-01 00:02:00|2020-10-01 00:03:00|        60|      0|\n",
      "|        3|1601510610|2020-10-01 00:03:00|2020-10-01 00:04:00|        60|      0|\n",
      "|        4|1601510670|2020-10-01 00:04:00|2020-10-01 00:05:00|        60|      0|\n",
      "|        5|1601510730|2020-10-01 00:05:00|2020-10-01 00:06:00|        60|      0|\n",
      "|        6|1601510790|2020-10-01 00:06:00|2020-10-01 00:07:00|        60|      0|\n",
      "|        7|1601510850|2020-10-01 00:07:00|2020-10-01 00:08:00|        60|      0|\n",
      "|        8|1601510910|2020-10-01 00:08:00|2020-10-01 00:09:00|        60|      0|\n",
      "|        9|1601510970|2020-10-01 00:09:00|2020-10-01 00:10:00|        60|      0|\n",
      "|       10|1601511030|2020-10-01 00:10:00|2020-10-01 00:11:00|        60|      0|\n",
      "|       11|1601511090|2020-10-01 00:11:00|2020-10-01 00:12:00|        60|      0|\n",
      "|       12|1601511150|2020-10-01 00:12:00|2020-10-01 00:13:00|        60|      0|\n",
      "|       13|1601511270|2020-10-01 00:14:00|2020-10-01 00:15:00|       120|      0|\n",
      "|       14|1601511330|2020-10-01 00:15:00|2020-10-01 00:16:00|        60|      0|\n",
      "|       15|1601511390|2020-10-01 00:16:00|2020-10-01 00:17:00|        60|      0|\n",
      "|       16|1601511570|2020-10-01 00:19:00|2020-10-01 00:20:00|       180|      0|\n",
      "|       17|1601511630|2020-10-01 00:20:00|2020-10-01 00:21:00|        60|      0|\n",
      "|       18|1601511690|2020-10-01 00:21:00|2020-10-01 00:22:00|        60|      0|\n",
      "|       19|1601511750|2020-10-01 00:22:00|2020-10-01 00:23:00|        60|      0|\n",
      "|       20|1601511810|2020-10-01 00:23:00|2020-10-01 00:24:00|        60|      0|\n",
      "|       21|1601511930|2020-10-01 00:25:00|2020-10-01 00:26:00|       120|      0|\n",
      "|       22|1601511990|2020-10-01 00:26:00|2020-10-01 00:27:00|        60|      0|\n",
      "|       23|1601512110|2020-10-01 00:28:00|2020-10-01 00:29:00|       120|      0|\n",
      "|       24|1601512170|2020-10-01 00:29:00|2020-10-01 00:30:00|        60|      0|\n",
      "|       25|1601512230|2020-10-01 00:30:00|2020-10-01 00:31:00|        60|      0|\n",
      "|       26|1601512290|2020-10-01 00:31:00|2020-10-01 00:32:00|        60|      0|\n",
      "|       27|1601512410|2020-10-01 00:33:00|2020-10-01 00:34:00|       120|      0|\n",
      "|       28|1601512470|2020-10-01 00:34:00|2020-10-01 00:35:00|        60|      0|\n",
      "|       29|1601512530|2020-10-01 00:35:00|2020-10-01 00:36:00|        60|      0|\n",
      "+---------+----------+-------------------+-------------------+----------+-------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BlockDF = BuildBlocks(df_final, max_interval = 300)\n",
    "BlockDF.select(\"window_id\",\"when\",\"window_start\",\"window_end\", \"TimeDiff_s\", \"BlockID\").show(30)\n",
    "\n",
    "#A questo punto sarebbe meglio fare il persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6b66f30a-d777-4eab-a6d4-5118c898dca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|BlockID|count|\n",
      "+-------+-----+\n",
      "|      0|  204|\n",
      "|      1|   16|\n",
      "|      2|   42|\n",
      "|      3|  104|\n",
      "|      4|  126|\n",
      "|      5|  317|\n",
      "|      6|  100|\n",
      "|      7|  518|\n",
      "|      8|  397|\n",
      "|      9|   54|\n",
      "|     10|  264|\n",
      "|     11|   71|\n",
      "|     12|   19|\n",
      "|     13|   99|\n",
      "|     14|  232|\n",
      "|     15|  320|\n",
      "|     16|   12|\n",
      "|     17|   88|\n",
      "|     18|  562|\n",
      "|     19|  196|\n",
      "|     20|   48|\n",
      "|     21|  255|\n",
      "|     22|   51|\n",
      "|     23| 1580|\n",
      "|     24|   70|\n",
      "|     25|  280|\n",
      "|     26|   83|\n",
      "|     27|  119|\n",
      "|     28|   72|\n",
      "|     29|   27|\n",
      "|     30|   67|\n",
      "|     31|  204|\n",
      "|     32|   68|\n",
      "|     33|  120|\n",
      "|     34|  238|\n",
      "|     35|   98|\n",
      "|     36|  195|\n",
      "|     37|  119|\n",
      "|     38|  165|\n",
      "|     39|   96|\n",
      "|     40|  109|\n",
      "|     41|    4|\n",
      "|     42|  151|\n",
      "|     43|   62|\n",
      "|     44|  106|\n",
      "|     45|   98|\n",
      "|     46|  938|\n",
      "|     47|  395|\n",
      "|     48|  245|\n",
      "|     49|   36|\n",
      "|     50|  174|\n",
      "|     51|  169|\n",
      "|     52|  178|\n",
      "|     53|  189|\n",
      "|     54|   78|\n",
      "|     55|   33|\n",
      "|     56|  211|\n",
      "|     57|  295|\n",
      "|     58|  609|\n",
      "|     59|   26|\n",
      "|     60|  121|\n",
      "|     61|  113|\n",
      "|     62|   51|\n",
      "|     63|   77|\n",
      "|     64|  197|\n",
      "|     65|   10|\n",
      "|     66|  429|\n",
      "|     67|  265|\n",
      "|     68|   89|\n",
      "|     69|  292|\n",
      "|     70|  713|\n",
      "|     71|  142|\n",
      "|     72|  125|\n",
      "|     73|  858|\n",
      "|     74|  158|\n",
      "|     75| 1301|\n",
      "|     76|  477|\n",
      "|     77| 1439|\n",
      "|     78|  356|\n",
      "|     79|   69|\n",
      "|     80|  723|\n",
      "|     81|  171|\n",
      "|     82|  240|\n",
      "|     83|   68|\n",
      "|     84|  132|\n",
      "|     85| 1529|\n",
      "|     86|    1|\n",
      "|     87|    1|\n",
      "|     88| 1414|\n",
      "|     89|   31|\n",
      "|     90| 1722|\n",
      "|     91|   88|\n",
      "|     92| 1044|\n",
      "|     93|  106|\n",
      "|     94|  749|\n",
      "|     95| 1159|\n",
      "|     96|  346|\n",
      "|     97|   89|\n",
      "|     98|   95|\n",
      "|     99|  376|\n",
      "+-------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BlockDF.groupBy(\"BlockID\").count().orderBy(\"BlockID\").show(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f6edf947-7fb3-40be-81ca-d95866d5a72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dist = BlockDF.groupBy(\"BlockID\").count().orderBy(\"BlockID\")\n",
    "\n",
    "data = Dist.toPandas()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(data['count'], bins = 50)\n",
    "plt.xlabel(\"block lenght\")\n",
    "#plt.ylabel(\"Number of Rows in Block\")\n",
    "plt.title(\"Block Size Distribution\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5239a7b3-8ab6-4e57-933c-018ae6f70561",
   "metadata": {},
   "source": [
    "### Block structure (MARCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "20762553-d385-4698-a1d6-1ce2c8bcc61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_blocks(df_final: DataFrame, frequency: int) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Build blocks using existing window_start for partitioning.\n",
    "    \n",
    "    Args:\n",
    "        df_final: Input Spark DataFrame with 'when' and 'window_start' columns.\n",
    "        frequency: Maximum allowed time gap in seconds.\n",
    "    Returns:\n",
    "        DataFrame with columns: 'window_id', 'block_id'.\n",
    "    \"\"\"\n",
    "    # 1) Extract date from existing window_start column for partitioning\n",
    "    df_with_day = df_final.withColumn(\"day\", to_date(col(\"window_start\")))\n",
    "    \n",
    "    # 2) Window partitioned by day, ordered by when\n",
    "    window_spec = Window.partitionBy(\"day\").orderBy(\"when\")\n",
    "    \n",
    "    # 3) Compute gap to previous timestamp within each day\n",
    "    df_with_gap = (df_with_day\n",
    "        .withColumn(\"prev_when\", lag(\"when\", 1).over(window_spec))\n",
    "        .withColumn(\"gap\", col(\"when\") - col(\"prev_when\"))\n",
    "    )\n",
    "    \n",
    "    # 4) Flag start of new block\n",
    "    df_with_flag = df_with_gap.withColumn(\n",
    "        \"is_new_block\",\n",
    "        when((col(\"prev_when\").isNull()) | (col(\"gap\") > frequency), 1).otherwise(0)\n",
    "    )\n",
    "    \n",
    "    # 5) Create daily block_id with partitioned window\n",
    "    df_with_daily_blocks = df_with_flag.withColumn(\n",
    "        \"daily_block_id\",\n",
    "        spark_sum(\"is_new_block\").over(window_spec)\n",
    "    )\n",
    "    \n",
    "    # 6) Create global block_id - get max blocks per day\n",
    "    daily_max = (df_with_daily_blocks\n",
    "        .groupBy(\"day\")\n",
    "        .agg(spark_max(\"daily_block_id\").alias(\"max_block\"))\n",
    "    )\n",
    "    \n",
    "    # 7) Calculate day offsets with partitioned window\n",
    "    day_window = Window.orderBy(\"day\")\n",
    "    daily_offsets = (daily_max\n",
    "        .withColumn(\"prev_max\", lag(\"max_block\", 1).over(day_window))\n",
    "        .withColumn(\"day_offset\", \n",
    "            spark_sum(when(col(\"prev_max\").isNull(), 0).otherwise(col(\"prev_max\"))).over(day_window))\n",
    "        .fillna(0, subset=[\"day_offset\"])\n",
    "        .select(\"day\", \"day_offset\")\n",
    "    )\n",
    "    \n",
    "    # 8) Join and create final block_id\n",
    "    result = (df_with_daily_blocks\n",
    "        .join(daily_offsets, \"day\")\n",
    "        .withColumn(\"block_id\", col(\"daily_block_id\") + col(\"day_offset\") - 1)\n",
    "        .select(\"window_id\", \"block_id\")\n",
    "        .orderBy(\"when\")  # Final sort by time\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 41,
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "id": "737b5966-b043-4d79-97f2-ac0836724fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blocks = build_blocks(df_final, frequency=120)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "be0fb073-a5df-43f1-9332-50fe31cf9f78",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 37,
   "id": "be0fb073-a5df-43f1-9332-50fe31cf9f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/01 07:37:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/01 07:37:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|window_id|block_id|\n",
      "+---------+--------+\n",
      "|        0|       0|\n",
      "|        1|       0|\n",
      "|        2|       0|\n",
      "|        3|       0|\n",
      "|        4|       0|\n",
      "|        5|       0|\n",
      "|        6|       0|\n",
      "|        7|       0|\n",
      "|        8|       0|\n",
      "|        9|       0|\n",
      "|       10|       0|\n",
      "|       11|       0|\n",
      "|       12|       0|\n",
      "|       13|       0|\n",
      "|       14|       0|\n",
      "|       15|       0|\n",
      "|       16|       1|\n",
      "|       17|       1|\n",
      "|       18|       1|\n",
      "|       19|       1|\n",
      "|       20|       1|\n",
      "|       21|       1|\n",
      "|       22|       1|\n",
      "|       23|       1|\n",
      "|       24|       1|\n",
      "|       25|       1|\n",
      "|       26|       1|\n",
      "|       27|       1|\n",
      "|       28|       1|\n",
      "|       29|       1|\n",
      "+---------+--------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
>>>>>>> 02dc1a699755c7a96517d9c47457f8f2510d2b36
   "source": [
    "df_blocks.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea97fd-7bde-403b-8020-ab78f691a423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final.join(df_blocks, on=\"window_id\", how=\"left\").select(\"block_id\",\"window_id\",\"window_start\").orderBy(\"window_id\").show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a539662d-3672-4ef4-9422-cb1644db9559",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_block_duration = (\n",
    "    df_blocks.groupBy(\"block_id\")\n",
    "    .count()\n",
    "    .withColumn(\"duration_minutes\", (col(\"count\") * lit(frequency)) / 60)\n",
    "    .drop(\"count\")\n",
    "    .orderBy(\"block_id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340ad1ed-b278-4a11-8b77-dc0d922946ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_block_duration.show(30,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23771bf-a689-49c4-bc51-dccf3858a2c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_block_stats = df_block_duration.groupBy(col(\"duration_minutes\").alias(\"block_length\")) \\\n",
    "    .agg(spark_count(\"*\").alias(\"block_count\")).orderBy(\"block_length\")\n",
    "df_block_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc22e7fa-6af6-4cfd-87e5-f7a7b621144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff_histogram(df_block_stats, min_length=1, max_length=100, step=1):\n",
    "    \"\"\"\n",
    "    Plot a histogram of contiguous block lengths.\n",
    "\n",
    "    Args:\n",
    "      df_block_stats: Spark DataFrame with ['block_length','block_count']\n",
    "      min_length:     smallest block_length to include\n",
    "      max_length:     largest block_length to include\n",
    "      step:           bar width\n",
    "    \"\"\"\n",
    "    pdf = (\n",
    "        df_block_stats\n",
    "        .filter((col(\"block_length\") >= min_length) &\n",
    "                (col(\"block_length\") <= max_length))\n",
    "        .orderBy(\"block_length\")\n",
    "        .toPandas()\n",
    "    )\n",
    "\n",
    "    if pdf.empty:\n",
    "        print(\"No blocks in the specified range.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(pdf[\"block_length\"], pdf[\"block_count\"], width=step, align=\"center\")\n",
    "    plt.xlabel(\"Block Length\")\n",
    "    plt.ylabel(\"Number of Blocks\")\n",
    "    plt.title(\"Histogram of Contiguous Block Lengths\")\n",
    "    plt.grid(True)\n",
    "    plt.xlim(min_length, max_length)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44872ac-7a65-499b-b0dd-48ccbd38a96d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_diff_histogram(df_block_stats, min_length=1, max_length=100, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485cb6e-6c4d-42cd-9232-6c14abaa16e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b43359f-a6ef-4ae2-a638-d87ad821b9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2bfa5d-3007-404b-8a08-0c70ce915c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "299f715d-63c1-4925-8f41-7bfc13ec3abe",
   "metadata": {},
   "source": [
    "### Anomaly detection (Raffaele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f9a30b-b7f2-49a2-9928-511fb064bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def resample_sensors(df, sensors, time_int):\n",
    "    \n",
    "    # Crea dataframe con sensori ricampionati. \n",
    "    \n",
    "    # Trovo istante iniziale\n",
    "    min_time = df.agg(spark_min(unix_timestamp('time')).alias('min_time')).collect()[0]['min_time']\n",
    "\n",
    "    # Creo lista di aggregatori da usare per mediare i dati vicini di ogni colonna\n",
    "    aggs = [mode(col(s)).alias(f\"mode_{s}\") for s in sensors] # mode prende il valore più frequente nel gruppo\n",
    "\n",
    "    # Creo df dove ogni dato della stessa colonna in [t, t+time_int] è mediato\n",
    "    resampled_df = df \\\n",
    "        .select('time', *sensors) \\\n",
    "        .withColumn('window_idx', spark_round((unix_timestamp(col('time'))-min_time)/time_int)) \\\n",
    "        .groupBy('window_idx').agg(*aggs) \\\n",
    "        .withColumn('sampling_time', from_unixtime(col('window_idx')*time_int + min_time)) \\\n",
    "        .withColumn('when', unix_timestamp(col('sampling_time'))) \\\n",
    "        .orderBy('sampling_time')\n",
    "    return resampled_df\n",
    "'''\n",
    "\n",
    "############################################################################\n",
    "\n",
    "\n",
    "def detect_switch_anomalies(df, sensors, window_minutes=10, switch_threshold=5):\n",
    "    \"\"\"\n",
    "    Crea un dataframe che contiene una flag per le anomalie di ogni sensore ogni window_minutes \n",
    "    NB: siccome la grid è spaziata di 1 minuto, window_minutes deve essere > 1 per avere senso\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract day (or hour) from timestamp to partition\n",
    "    df = df \\\n",
    "        .select('when', *sensors, 'window_start', 'window_end') \\\n",
    "        .withColumn(\"day\", to_date(col('window_start')))\n",
    "\n",
    "    # Lag to get previous value within each partition --- OTHERWISE IT MOVES ALL IN THE SAME PARTITION \n",
    "    w_lag = Window.partitionBy(\"day\").orderBy(\"when\")\n",
    "    lagged_columns = [lag(col(s)).over(w_lag) for s in sensors] # per ogni sensore prendo le righe shiftate di 1 all'indietro\n",
    "    lag_names      = [f\"lagged_{s}\" for s in sensors]\n",
    "    \n",
    "    df_lagged = df.withColumns(dict(zip(lag_names, lagged_columns)))\n",
    "\n",
    "    # Detect change 0→1 or 1→0\n",
    "    didSwitch   = [when((col(f\"lagged_{s}\") != col(s)), 1).otherwise(0) for s in sensors] # per ogni sensore verifico se il valore è cambiato rispetto al precedente \n",
    "    switch_names = [f\"switch_{s}\" for s in sensors]\n",
    "    \n",
    "    df_changes = df_lagged.withColumns(dict(zip(switch_names, didSwitch)))\n",
    "\n",
    "    # Rolling window over time with partition\n",
    "    # Raffaele: così rischiamo di contare più volte la stessa anomalia.\n",
    "     '''\n",
    "    w_time = Window.partitionBy(\"day\").orderBy(\"when\").rangeBetween(-window_minutes * 60, 0)\n",
    "    change_counts = [spark_sum(f\"switch_{s}\").over(w_time) for s in sensors]\n",
    "    counts_names  = [f\"change_count_{s}\" for s in sensors]\n",
    "    \n",
    "    df_windowed = df_changes.withColumns(dict(zip(counts_names, change_counts)))\n",
    "     '''\n",
    "    w_group = Window.orderBy('when')\n",
    "    w_count = Window.partitionBy('groupId')\n",
    "    \n",
    "    df_switch_group = (\n",
    "        df_changes \\\n",
    "        .withColumn('switch_group', when(lag(col('switch_S117')) != col('switch_S117'), 1).otherwise(0)) \\\n",
    "        .withColumn('groupId', spark_sum('switch_group').over(w_group)) \\\n",
    "        .withColumn('')\n",
    "    )\n",
    "\n",
    "    # Flag anomaly\n",
    "    anomalies       = [col(f\"change_count_{s}\") > switch_threshold for s in sensors]\n",
    "    anomalies_names = [f\"{s}_anomaly\" for s in sensors]\n",
    "    \n",
    "    df_anomaly = df_windowed \\\n",
    "    .withColumns(dict(zip(anomalies_names, anomalies))) \\\n",
    "    .drop(*lag_names, *switch_names, *counts_names, \"day\", \"window_idx\")\n",
    "\n",
    "    return df_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49728a35-64fc-4b0e-a6ad-08cd647d26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = ['S117', 'S118', 'S169', 'S170']\n",
    "anomalies = detect_switch_anomalies(\n",
    "  df= df_final,\n",
    "  sensors=sensors,\n",
    "  window_minutes=60,\n",
    "  switch_threshold=6\n",
    ")\n",
    "\n",
    "# Per confronto vediamo se le anomalie del S117 corrispondono a quelle del metodo di Marco:\n",
    "anomalies \\\n",
    "    .show(10, truncate=False)\n",
    "\n",
    "# Questo non va ancora\n",
    "#filters = [col(f\"mode_{s}_anomaly\") for s in sensors] \n",
    "#total_filter = filters[0]\n",
    "#for i in range(1, len(filters)):\n",
    "#    total_filter = total_filter & filters[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb4ae3f-7772-4400-9541-bc41f9f587d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anomaly_hist(df, sensors, time_start, time_end):\n",
    "    '''\n",
    "    Plotta il numero di anomalie al giorno per ogni sensore, nell'arco di tempo [time_start, time_end]\n",
    "    '''\n",
    "\n",
    "    casts = [col(f'{s}_anomaly').cast('Int') for s in sensors] # per convertire i booleani in S_anomaly in 0/1 \n",
    "    aggs = [spark_sum(col(f'{s}_anomaly')).alias(f'anomaly_count_{s}') for s in sensors] # per contare le anomalie ogni giorno\n",
    "\n",
    "    new_df = df \\\n",
    "    .select('when', 'window_start', 'window_end', *[f\"{s}_anomaly\" for s in sensors]) \\\n",
    "    .filter(col('when').between(time_start, time_end)) \\\n",
    "    .withColumn('day', to_date(col('window_start'))) \\\n",
    "    .withColumns(dict(zip([f'{s}_anomaly' for s in sensors], casts))) \\\n",
    "    .groupBy('day').agg(*aggs) \\\n",
    "    .orderBy('day')\n",
    "\n",
    "    n_sensors = len(sensors)\n",
    "    fig, axes = plt.subplots(ceil(n_sensors/2), 2, figsize=(20, 5))\n",
    "    days = new_df.select('day').rdd.flatMap(lambda x: x).collect()\n",
    "    for i in range(n_sensors):\n",
    "        counts = new_df.select(f'anomaly_count_{sensors[i]}').rdd.flatMap(lambda x: x).collect()\n",
    "        idx = i if n_sensors <= 2 else (i//2, i%2)\n",
    "        axes[idx].bar(days, counts)\n",
    "        axes[idx].set_title(f'anomaly_count_{sensors[i]}')\n",
    "        axes[idx].set(xlabel=\"day\", ylabel=\"counts\")\n",
    "        #print(sensors[i], counts)\n",
    "    fig.tight_layout()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e15d87-3ea8-426e-b432-5a94d04aed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anomaly_hist(anomalies, ['S117', 'S118', 'S169', 'S170'], 1602879000, 1602879000+10000000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f463a-5d59-43b2-854e-f69d3d866df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f98d6-1af1-4e82-8c7e-46b25d3b9479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237cc736-c6eb-48c5-ae48-605ecaacdc71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e90eec7a-6138-4167-8f78-58bafab1248e",
   "metadata": {},
   "source": [
    "# <hr style=\"height:4px; background-color:black; border:none;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fca02a0-e945-4d6a-9e70-237afb583c78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Su solo una colonna (metodo nearest) FUNZIONANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb44695-86d4-4d5d-8af8-93de34608f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_sensor_simple(\n",
    "    df_hard: DataFrame,\n",
    "    sensor: str,\n",
    "    interval: int = 60\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Resample a single sensor column to regular intervals using the nearest non-null value.\n",
    "\n",
    "    Args:\n",
    "        df_hard:   Spark DataFrame with columns ['when', sensor].\n",
    "        sensor:    Name of the sensor column (e.g., 'S117').\n",
    "        interval:  Resample interval in seconds.\n",
    "\n",
    "    Returns:\n",
    "        Resampled DataFrame with ['when', sensor, 'time'], using only non-null nearest values.\n",
    "    \"\"\"\n",
    "    spark = df_hard.sparkSession\n",
    "    half = interval / 2\n",
    "\n",
    "    # 1. Create target timestamp grid\n",
    "    bounds = df_hard.selectExpr(\"min(when) as min_t\", \"max(when) as max_t\").first()\n",
    "    min_t, max_t = bounds.min_t, bounds.max_t\n",
    "\n",
    "    grid_df = (\n",
    "        spark.range(1)\n",
    "             .selectExpr(f\"sequence({min_t}, {max_t}, {interval}) as times\")\n",
    "             .select(explode(\"times\").alias(\"target_when\"))\n",
    "    )\n",
    "\n",
    "    # 2. Range join within ±half interval and exclude NULLs before aggregation\n",
    "    joined = (\n",
    "        df_hard\n",
    "          .select(\"when\", sensor)\n",
    "          .filter(col(sensor).isNotNull())  # <-- filter out nulls before min_by\n",
    "          .join(\n",
    "              grid_df,\n",
    "              (col(\"when\") >= col(\"target_when\") - half) &\n",
    "              (col(\"when\") <= col(\"target_when\") + half),\n",
    "              how=\"inner\"\n",
    "          )\n",
    "          .withColumn(\"time_diff\", abs_(col(\"when\") - col(\"target_when\")))\n",
    "    )\n",
    "\n",
    "    # 3. Pick value with minimum time difference (nearest non-null)\n",
    "    result = (\n",
    "        joined.groupBy(\"target_when\")\n",
    "              .agg(min_by(col(sensor), col(\"time_diff\")).alias(sensor))\n",
    "    )\n",
    "\n",
    "    # 4. Format output\n",
    "    final = (\n",
    "        result\n",
    "          .withColumnRenamed(\"target_when\", \"when\")\n",
    "          .withColumn(\"time\", from_unixtime(col(\"when\")))\n",
    "          .orderBy(\"when\")\n",
    "    )\n",
    "\n",
    "\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89425435-d21b-4e22-8357-4074901dc376",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_resampled_S117 = resample_sensor_simple(df_hard, \"A5\", interval=60)\n",
    "df_resampled_S117.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7326d19b-fcfc-4259-a540-b36a948b1297",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Various checks to show that everything works (questi li terrei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a520425d-e090-433c-96f1-20fdbddce8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a specific region\n",
    "start_ts = 1601526622\n",
    "end_ts   = 1601531000\n",
    "\n",
    "df_resampled_S117.filter(\n",
    "    (col(\"when\") >= start_ts) & \n",
    "    (col(\"when\") <= end_ts)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec865f-5198-4bc9-9ad7-74b2d9b0ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect(df_hard, sensors=[\"S117\"], start=1601526622, end=1601531000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1bdac-8a39-451c-9c8e-52d60b9ea15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect(df_hard, sensors=[\"S117\"], start=1601527100, end=1601529400).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5de846-c5a6-4ad1-8121-3df91435ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check everything is fine\n",
    "\n",
    "# Compute time differences\n",
    "rdd_diff_S117 = compute_time_differences(df_resampled_S117)\n",
    "\n",
    "# Summarize and print top/bottom time gaps\n",
    "df_diff_summary_S117 = time_diff_summary(rdd_diff_S117, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dce3a2-75a5-430a-b18b-6e5f4f35a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questo dai dati di prima, sembra funzionare\n",
    "# |5003774|1    |\n",
    "# |2066908|1    |\n",
    "# |757864 |1    |\n",
    "# |48451  |1    |\n",
    "# |28598  |1    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff157f-db7d-489b-8873-cd4416380597",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### data blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2198e8-7fc1-4d5b-b7b8-eca3b743769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_contiguous_blocks(\n",
    "    df: DataFrame,\n",
    "    interval: int,\n",
    "    col_when: str = \"when\"\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Count contiguous blocks of rows spaced exactly `interval` seconds apart,\n",
    "    partitioned by day for parallelism.\n",
    "\n",
    "    Args:\n",
    "      df:         Spark DataFrame with a timestamp column in seconds.\n",
    "      interval:   Expected spacing between consecutive rows (in seconds).\n",
    "      col_when:   Name of that timestamp column (default 'when').\n",
    "\n",
    "    Returns:\n",
    "      DataFrame with columns:\n",
    "        - block_length: number of rows in each contiguous block\n",
    "        - block_count:  how many such blocks exist\n",
    "    \"\"\"\n",
    "    # 1) Add a 'day' column for partitioning\n",
    "    df2 = df.withColumn(\"day\", to_date(from_unixtime(col(col_when))))\n",
    "\n",
    "    # 2) Window over each day, ordered by timestamp\n",
    "    w = Window.partitionBy(\"day\").orderBy(col(col_when))\n",
    "\n",
    "    # 3) Compute the gap to the previous timestamp\n",
    "    df3 = (\n",
    "        df2\n",
    "        .withColumn(\"prev_when\", lag(col(col_when), 1).over(w))\n",
    "        .withColumn(\"gap\", col(col_when) - col(\"prev_when\"))\n",
    "    )\n",
    "\n",
    "    # 4) Flag start of new block when gap != interval (or first in day)\n",
    "    df4 = df3.withColumn(\n",
    "        \"is_new_block\",\n",
    "        expr(f\"CASE WHEN gap IS NULL OR gap != {interval} THEN 1 ELSE 0 END\")\n",
    "    )\n",
    "\n",
    "    # 5) Cumulative sum over the window to assign a block_id\n",
    "    df5 = df4.withColumn(\n",
    "        \"block_id\",\n",
    "        sum_(col(\"is_new_block\")).over(w)\n",
    "    )\n",
    "\n",
    "    # 6) Count rows per (day, block_id) → this is block_length\n",
    "    blocks = (\n",
    "        df5\n",
    "        .groupBy(\"day\", \"block_id\")\n",
    "        .agg(count(\"*\").alias(\"block_length\"))\n",
    "    )\n",
    "\n",
    "    # 7) Count how many blocks have each length across all days\n",
    "    result = (\n",
    "        blocks\n",
    "        .groupBy(\"block_length\")\n",
    "        .agg(count(\"*\").alias(\"block_count\"))\n",
    "        .orderBy(\"block_length\")\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2ca2b-a4fa-4d2a-a6c8-4087f351ac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff_histogram(df_block_stats, min_length=1, max_length=100, step=1):\n",
    "    \"\"\"\n",
    "    Plot a histogram of contiguous block lengths.\n",
    "\n",
    "    Args:\n",
    "      df_block_stats: Spark DataFrame with ['block_length','block_count']\n",
    "      min_length:     smallest block_length to include\n",
    "      max_length:     largest block_length to include\n",
    "      step:           bar width\n",
    "    \"\"\"\n",
    "    pdf = (\n",
    "        df_block_stats\n",
    "        .filter((col(\"block_length\") >= min_length) &\n",
    "                (col(\"block_length\") <= max_length))\n",
    "        .orderBy(\"block_length\")\n",
    "        .toPandas()\n",
    "    )\n",
    "\n",
    "    if pdf.empty:\n",
    "        print(\"No blocks in the specified range.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(pdf[\"block_length\"], pdf[\"block_count\"], width=step, align=\"center\")\n",
    "    plt.xlabel(\"Block Length\")\n",
    "    plt.ylabel(\"Number of Blocks\")\n",
    "    plt.title(\"Histogram of Contiguous Block Lengths\")\n",
    "    plt.grid(True)\n",
    "    plt.xlim(min_length, max_length)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef75a4e-3df8-4478-96cc-fe428203f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Select only the timestamp column\n",
    "df_sample = df_resampled_S117.select(\"when\")\n",
    "\n",
    "# 2) Compute contiguous block stats at 60s spacing\n",
    "block_stats = count_contiguous_blocks(df_sample, interval=60)\n",
    "\n",
    "# 3) Inspect\n",
    "block_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a96ce-c606-4b71-a820-587c173eda37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Plot histogram for blocks length 1–1000\n",
    "plot_diff_histogram(block_stats, min_length=1, max_length=100, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d373b431-09fb-4be5-b205-237db8c42fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041b6528-8c7c-45c1-98b7-d64548d488d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bf311c7-91c5-42c2-b69d-4ce24bee430e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Con vari metodi riempimento (near,min,max,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6920ce8-101c-4288-aba4-92ff27f528cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_sensor(\n",
    "    df_hard: DataFrame,\n",
    "    sensor: str,\n",
    "    interval: int = 60,\n",
    "    method: str = \"near\"\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Resample a single sensor column to regular intervals.\n",
    "\n",
    "    Args:\n",
    "      df_hard:   DataFrame with 'when' (in seconds) and the sensor column.\n",
    "      sensor:    name of the sensor column (e.g. 'S117').\n",
    "      interval:  interval in seconds (e.g. 60).\n",
    "      method:    one of 'near', 'min', 'max', 'mean'.\n",
    "\n",
    "    Returns:\n",
    "      DataFrame with columns ['when', sensor, 'time'] at regular timestamps.\n",
    "      All values are non-null. If no data is found for a window, the row is skipped.\n",
    "    \"\"\"\n",
    "    spark = df_hard.sparkSession\n",
    "    half = interval / 2\n",
    "\n",
    "    # Validate method\n",
    "    if method not in (\"near\", \"min\", \"max\", \"mean\"):\n",
    "        raise ValueError(f\"Unsupported method '{method}'. Choose from 'near', 'min', 'max', 'mean'.\")\n",
    "\n",
    "    # 1. Create time grid\n",
    "    bounds = df_hard.selectExpr(\"min(when) as min_t\", \"max(when) as max_t\").first()\n",
    "    min_t, max_t = bounds.min_t, bounds.max_t\n",
    "\n",
    "    grid_df = (\n",
    "        spark.range(1)\n",
    "             .selectExpr(f\"sequence({min_t}, {max_t}, {interval}) as times\")\n",
    "             .select(explode(\"times\").alias(\"target_when\"))\n",
    "    )\n",
    "\n",
    "    # 2. Join with range ± half interval and exclude NULLs before aggregation\n",
    "    filtered = df_hard.select(\"when\", sensor).filter(col(sensor).isNotNull())\n",
    "\n",
    "    joined = (\n",
    "        filtered\n",
    "          .join(\n",
    "              grid_df,\n",
    "              (col(\"when\") >= col(\"target_when\") - half) &\n",
    "              (col(\"when\") <= col(\"target_when\") + half),\n",
    "              how=\"inner\"\n",
    "          )\n",
    "          .withColumn(\"time_diff\", abs_(col(\"when\") - col(\"target_when\")))\n",
    "    )\n",
    "\n",
    "    # 3. Aggregate based on method\n",
    "    if method == \"near\":\n",
    "        agg_expr = min_by(col(sensor), col(\"time_diff\")).alias(sensor)\n",
    "    elif method == \"min\":\n",
    "        agg_expr = spark_min(col(sensor)).alias(sensor)\n",
    "    elif method == \"max\":\n",
    "        agg_expr = spark_max(col(sensor)).alias(sensor)\n",
    "    else:  # mean\n",
    "        agg_expr = spark_avg(col(sensor)).alias(sensor)\n",
    "\n",
    "    result = (\n",
    "        joined.groupBy(\"target_when\")\n",
    "              .agg(agg_expr)\n",
    "    )\n",
    "\n",
    "    # 4. Final formatting\n",
    "    final = (\n",
    "        result\n",
    "          .withColumnRenamed(\"target_when\", \"when\")\n",
    "          .withColumn(\"time\", from_unixtime(col(\"when\")))\n",
    "          .orderBy(\"when\")\n",
    "    )\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148d2465-73f7-469c-a076-0b632c8148dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest‐time fill\n",
    "df_near = resample_sensor(df_hard, \"S117\", interval=60, method=\"near\")\n",
    "df_near.show(5)\n",
    "\n",
    "# Minimum‐value fill\n",
    "df_min = resample_sensor(df_hard, \"S117\", interval=60, method=\"min\")\n",
    "df_min.show(5)\n",
    "\n",
    "# Maximum‐value fill\n",
    "df_max = resample_sensor(df_hard, \"S117\", interval=60, method=\"max\")\n",
    "df_max.show(5)\n",
    "\n",
    "# Mean‐value fill\n",
    "df_mean = resample_sensor(df_hard, \"S117\", interval=60, method=\"mean\")\n",
    "df_mean.show(5)\n",
    "\n",
    "# Invalid method raises:\n",
    "# resample_sensor(df_hard, \"S117\", 60, method=\"median\")\n",
    "# → ValueError: Unsupported method 'median'. Choose from 'near', 'min', 'max', 'mean'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25499f6d-09e4-4fb4-9a90-b0460fcd5519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775cbdbb-e618-4c4a-a9e2-d0d144bf1c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b61fd-e032-4c3c-963e-29e465736e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc527f-30c0-4221-bd42-0f2e2e583742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROVA MARCO VECCHIA CONVERSIONE SENSORI A5 A9, ricopiata il codice può essere utile\n",
    "# --- OCCHIO --- questo ti pare che faccia la conversione del binario da dx verso sx, dovrebbe essere il contrario\n",
    "\n",
    "# def convert_a5_to_binary_bits(df,sensor):\n",
    "#     df_with_bits = df\n",
    "    \n",
    "#     for i in range(16):\n",
    "#         bit_position = 15 - i  # S1 = bit 15 (leftmost), S16 = bit 0 (rightmost)\n",
    "#         df_with_bits = df_with_bits.withColumn(\n",
    "#             f\"YOLO{i+1}\",\n",
    "#             (  col(sensor).bitwiseAND(1 << bit_position)  > 0 ).cast(\"int\")\n",
    "#         )\n",
    "    \n",
    "#     return df_with_bits\n",
    "\n",
    "# # Usage\n",
    "# df_with_binary = convert_a5_to_binary_bits(df_pivoted,\"A5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b53382d-ff59-4872-b543-79315fdac955",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Anomaly detection (Prova Marco sarà da cancellare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba3e04d-c6d4-4477-83ae-97221ac42da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_switch_anomaly(df, sensor, window_minutes=10, switch_threshold=5):\n",
    "    \"\"\"\n",
    "    Detects frequent switching for binary sensor, partitioned by day to avoid single-node pressure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract day (or hour) from timestamp to partition\n",
    "    df = df.withColumn(\"day\", to_date(from_unixtime(col(\"when\"))))\n",
    "\n",
    "    # Lag to get previous value within each partition --- OTHERWISE IT MOVES ALL IN THE SAME PARTITION\n",
    "    w_lag = Window.partitionBy(\"day\").orderBy(\"when\")\n",
    "    df_lagged = df.withColumn(\"prev\", lag(col(sensor)).over(w_lag))\n",
    "\n",
    "    # Detect change 0→1 or 1→0\n",
    "    df_changes = df_lagged.withColumn(\n",
    "        \"change\", when((col(\"prev\") != col(sensor)), 1).otherwise(0)\n",
    "    )\n",
    "\n",
    "    # Rolling window over time with partition\n",
    "    w_time = Window.partitionBy(\"day\").orderBy(\"when\").rangeBetween(-window_minutes * 60, 0)\n",
    "    df_windowed = df_changes.withColumn(\n",
    "        \"change_count\", sum_(\"change\").over(w_time)\n",
    "    )\n",
    "\n",
    "    # Flag anomaly\n",
    "    df_anomaly = df_windowed.withColumn(\n",
    "        \"is_anomaly\", (col(\"change_count\") > switch_threshold)\n",
    "    ).drop(\"prev\", \"change\", \"change_count\", \"day\")\n",
    "\n",
    "    return df_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849c25c-a75f-494b-b8ac-dcafe6e3ecf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_anom = detect_switch_anomaly(\n",
    "  df_resampled_S117,\n",
    "  sensor=\"S117\",\n",
    "  window_minutes=60,\n",
    "  switch_threshold=6\n",
    ")\n",
    "df_anom.filter(\"is_anomaly\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d81b03a-aecd-46ae-aa92-d7ff6b6a7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini = 1602882742-50*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ce942-07b8-49df-8664-b7dcba64f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine =1602882742+50*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979993d2-4313-4a1f-988c-156c1c6e7e0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inspect(df_resampled_S117, sensors=[\"S117\"], start=ini, end=fine).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28753c-c068-4334-84de-1b6e141a9603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67fecb82-d909-4dc6-a026-16d5347faaa7",
   "metadata": {},
   "source": [
    "# Predictive Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b6c25-4344-4d39-b74f-886da19b1aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff72c85-a4cb-4486-adf4-4bb541f5e867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c282937a-70c2-4cd6-a0f3-85864215978e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9167f121-b1ef-4e2c-bf48-07f55a14afad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604ef5e-bbb2-4528-ab5c-b6901b18a4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a8d74-a326-4733-a3f7-157b2b1ad302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c34c12-7e6b-44c1-99be-3a8635e2a905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7593e0-7c05-4ff3-a3b8-6f0f6f24ce16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2930c16b-276b-4e9a-b7b2-78a9e82c0776",
   "metadata": {},
   "source": [
    "# *** Remember to close Spark Session ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33c131-fe4d-4135-8844-5d1015fb0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2f446-cd02-4d0d-a3d9-f501963a87be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41fcced-1f35-4f53-b9bc-ba8e97617d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57265f1f-2d05-47e5-8427-099e79949cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
