{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b76336-8f50-45ca-8605-531a1f1e9817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/02 17:53:12 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/opt/miniconda3/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/opt/miniconda3/bin/python\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"User_B_Session\") \\\n",
    "    .master(\"spark://10.67.22.135:7077\") \\\n",
    "    .config(\"spark.scheduler.mode\", \"FAIR\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"false\") \\\n",
    "    .config(\"spark.shuffle.service.enabled\", \"false\") \\\n",
    "    .config(\"spark.scheduler.pool\", \"user_b\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9314cb27-e360-4e56-89c5-f46e83be3207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SparkContext initialized.\n",
      "✅ Created RDD with 8 partitions\n",
      "✅ Result of reduceByKey: [(0, 2500), (1, 2500), (2, 2500), (3, 2500)]\n",
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  0|Name0|\n",
      "|  1|Name1|\n",
      "|  2|Name2|\n",
      "|  3|Name3|\n",
      "|  4|Name4|\n",
      "|  5|Name5|\n",
      "|  6|Name6|\n",
      "|  7|Name7|\n",
      "|  8|Name8|\n",
      "|  9|Name9|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "\n",
    "print(\"✅ SparkContext initialized.\")\n",
    "\n",
    "# Create an RDD with 8 partitions to make sure all workers get work\n",
    "num_partitions = 8\n",
    "data = list(range(1, 10001))\n",
    "rdd = sc.parallelize(data, num_partitions)\n",
    "\n",
    "print(f\"✅ Created RDD with {rdd.getNumPartitions()} partitions\")\n",
    "\n",
    "# Force a distributed job with a shuffle\n",
    "word_pairs = rdd.map(lambda x: (x % 4, 1))  # 4 keys, but partitions = 8\n",
    "counts = word_pairs.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "result = counts.collect()\n",
    "print(\"✅ Result of reduceByKey:\", result)\n",
    "\n",
    "# Optional: also run DataFrame work\n",
    "df = spark.createDataFrame([(i, f\"Name{i}\") for i in range(10)], [\"id\", \"name\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c16584-176c-4f4f-81b2-945801aee748",
   "metadata": {},
   "source": [
    "Se la cella di sopra ha prodotto un risultato del tipo:\\\n",
    "✅ SparkContext initialized.\\\n",
    "✅ Created RDD with 8 partitions\\\n",
    "✅ Result of reduceByKey: [(0, 2500), (1, 2500), (2, 2500), (3, 2500)]\\\n",
    "+---+-----+\n",
    "| id| name|\n",
    "+---+-----+\n",
    "|  0|Name0|\n",
    "|  1|Name1|\n",
    "|  2|Name2|\n",
    "|  3|Name3|\n",
    "|  4|Name4|\n",
    "|  5|Name5|\n",
    "|  6|Name6|\n",
    "|  7|Name7|\n",
    "|  8|Name8|\n",
    "|  9|Name9|\n",
    "+---+-----+\\\n",
    "Allora siamo a cavallo, dovreste vedere nella pagina del locahost User session il lavoro distribuito su 11 cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f89e5a-09b0-4a99-93c8-bed8cc88222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815fc5db-1a09-4b7c-bad4-bfa840e0bdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
